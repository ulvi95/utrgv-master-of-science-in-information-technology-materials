In this post, I share my opinions regarding the topics discussed in articles and podcasts and the possible problems in the design process provided by them.

Even from the beginning of human civilization, people tend to project human qualities to animals and inanimate things. Here, we can see the first problem that is people expect the same human qualities and behavior from the robotic objects. In the "Lets Talk About Race", it might be seen how this task difficult is. Due to the fact that even we train either the robots or NN systems properly, we cannot see how the system is educated by itself. Even with the perfect data, the systems could not get the context related to the data. On the other side, it is also difficult to prepare huge data for the system to train. As the result, the behavior and the provided suggestions might be counter-intuitive and even non-acceptable from the human side.

The projection also might lead to the situation that the people could describe their behavior against the robots as they are human. For example, in the podcast "I, Robot: Our Changing Relationship with Technology" is discussed how the users provide their questions and the private data to Google, being shocked that how the search engine could know their taste and opinions.

The second problem is how the interaction between robots and humans. There are three sub-problems: The first one is that the "gender" of robots might totally change the manner of how the information is accepted, which is described in "Exploring the Role of Gender in Perceptions of Robotic Noncompliance". Knowing this, the designers should have some options to alter the sound to feminize/masculinize so that the user could be satisfied. The second sub-problem is described in "When the Interface Is a Face": When there is some interface with some human qualities, people tend to feel the discomfort from human presence, even there is no human. And the third sub-problem comes from the fact that it is impossible to understand the context from the question, which is also described in "On Perceived Social and Moral Agency in Natural Language Capable Robots".

The third main problem is the linguistics design discussed in "The Power of Linguistics: Unpacking Natural Language". The case that the translation from human language to the language robot understands is a very difficult task even in a simple language like Modern English. The problem gets much harder in languages with a lot of genders, suffixes, and prefixes, such as French, German, Arabic, etc.

In my opinion, to solve these problems, it is important for both philosophers and designers to answer the question: should we expect the humanistic behavior from the robots, or just accept them as some device?