During this week, I have read several materials describing people's behavior against the devices and how the conditions affect behavior. The first problem is how people understand what the device is. Usually, kids assume them as some toy, so they can "joke" with them using cruel sentences, and get some answer. There are two sub-problems: The first one described is that the people should understand that such devices are not some training apparatus to train/relax with, because commands might be collected, and even executed. The second sub-problem is humanizing a device. Should the device have some "ethics" to restrict user's unacceptable behavior? The article "Language-Capable Robots may Inadvertently Weaken Human Moral Norms" described that the robots couldn't evaluate how the behavior is harmful if the question has some ambiguity. Another article named "We tested bots like Siri and Alexa to see who would stand up to sexual harassment." also described that the devices could not handle the commands with a sexual context properly. In my opinion, the devices should not have any ethical setups, but in this case, the interaction must be regulated by rules and law to define who is (either the owner of the device or the company) responsible for the accidents.

The second problem is how anonymity and invisibility could affect the behavior on the Internet. Here, the main thing that the conversation occurs virtually. Here, I provide my opinions from the Breakout room I participated: While the non-verbal behavior takes more than 50% in the regular conversation, we cannot evaluate in the virtual conversation if the people are lying or saying what they think. Especially, we cannot define the eye-contact on our own. The possible solution is to design specific software to evaluate the position of eyes.

In addition to the provided statements, people usually tend to think that they couldn't be defined and identified. As the result, the negative behavior increases, since knowing some "invisibility", people take more risk than usual. This problem is provided in the article "Effects of anonymity, invisibility, and lack of eye-contact on toxic online disinhibition". Here, people should be acknowledged with the ways of identification on the Internet so that people start to behave calmer.

The third problem is the possible radicalization on the Internet. This problem is analyzed in the article "Auditing Radicalization Pathways on YouTube". I don't think that the problem is analyzed from the right angle. Firstly, there is no data regarding "medium" channels (for example, [right-/left-] centrist, such as liberals, etc.) so that we cannot compare how the proportion of the radical channels is. Secondly, it would be better to analyze such channels in other languages, such as Spanish, Russian, etc. Thirdly, we cannot say either they have fun on the Internet or write seriously. Maybe, it is some way to transfer their negative in the real life. Because usually, the proportion of people with radical views in the democratic countries are very low.

According to the provided rubric, I would evaluate my participation as 5/5.